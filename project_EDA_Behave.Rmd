---
title: "project_EDA"
author: "Yu Zhu"
date: "10/26/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Behavior Data
## I. Data Description
### 1.1 Import data
```{r}
library(readxl)
Behave <- read_excel("~/Desktop/ucsc/courses/stat 204/project/ProjectDataset_behave.xlsx")
```

### 1.2 Summarization
```{r}
summary(Behave)
```
```{r}
str(Behave)
```
```{r}
head(Behave)
```

```{r}
table(Behave$ParticipantNum)
table(Behave$Confidence)
```
### 1.3 Check Missing Data

```{r}
which(is.na(Behave))
```
No missing data found. Great!

```{r}

library(naniar)
vis_miss(Behave)
```

```{r}
library(ggplot2)
p <- ggplot(Behave, aes(x=ResponseTime)) + 
  geom_histogram(binwidth=0.1, alpha=0.9, fill="#69b3a2", color="#e9ecef") +
  ggtitle("Histogram of Response Time")
p
```


```{r}
library(dplyr)
library(hrbrthemes)

Accurate_RT = Behave$ResponseTime[Behave$Accuracy == 1]
Inaccurate_RT = Behave$ResponseTime[Behave$Accuracy == 0]
acc_data <- data.frame(
  type = c( rep("Response Time under Accurate Decision", length(Accurate_RT)), rep("Response Time under Inaccurate Decision", length(Inaccurate_RT)) ),
  value = c( Accurate_RT, Inaccurate_RT )
)

# Represent it
p <- acc_data %>%
  ggplot( aes(x=value, fill=type)) +
    geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
    scale_fill_manual(values=c("#69b3a2", "#404080")) +
    labs(fill="")
p
```

### 1.4 Factorization

```{r}
Behave$ParticipantNum = as.factor(Behave$ParticipantNum)
Behave$Confidence = as.factor(Behave$Confidence)
Behave$StrengthLevel = as.factor(Behave$StrengthLevel)
```

```{r}
# Show the frequency of the variables
table(Behave$ParticipantNum)
table(Behave$Confidence)
table(Behave$StrengthLevel)
table(Behave$Accuracy)
```

## II. Explotary Data Analysis
### 2.1 Contingency tables

```{r}
# Strength level VS Participant Number
table(Behave$StrengthLevel, Behave$ParticipantNum)
```

```{r}
# Strength Level vs Confidence
library(vcd)
tb_Str_Conf = table(Behave$StrengthLevel, Behave$Confidence); tb_Str_Conf
mosaicplot(tb_Str_Conf, main="Confidence vs Strength Level", xlab="Strength", ylab="Confidence",shade=TRUE)
chisq.test(tb_Str_Conf) ### Perform independence test in detail later
```
Obviously, the larger the confidence, the more accurate the experiment.


```{r}
# Acc VS Strength Level
tb_Stren_Acc = table(Behave$StrengthLevel, Behave$Accuracy); tb_Stren_Acc
mosaicplot(tb_Stren_Acc, shade = TRUE, main="Accuracy vs Strength Level", xlab="Strength Level", ylab="Accuracy")
chisq.test(tb_Stren_Acc) ### Perform independence test in detail later
```
Obviously, the larger the strength level, the more accurate the experiment.



```{r}
Behave_1 = data.frame(Behave$Confidence,Behave$StrengthLevel, Behave$Accuracy)
ftable(table(Behave_1))
```

### 2.2 Boxplot of Reponse time Vs Accuracy and Reponse time Vs Confidence

```{r}
par(mfrow = c(1,2))
boxplot(Behave$ResponseTime~Behave$Accuracy, xlab = "Accuracy", ylab = "Response Time", col=rgb(0.3,0.5,0.4,0.6))
boxplot(Behave$ResponseTime~Behave$Confidence, xlab = "Confidence", ylab = "Response Time", col="#69b3a2")

#boxplot(Behave$ResponseTime~Behave$StrengthLevel, xlab = "Strength Level", ylab = "Response Time")
```

From the boxplots, there shows the pattern that the response time decrease along with the increasing of strength level and confidence.


### 2.3 Accuracy rate 
#### Barplot
Here I tried to transfer ACC into accuracy rate, taking means for each participant

```{r}
agg.ParticipantNum = aggregate(Accuracy~ParticipantNum, data = Behave,  mean)
agg.ParticipantNum_len = aggregate(Accuracy~ParticipantNum, 
                        data = Behave,  length)
agg.ParticipantNum_sd = aggregate(Accuracy~ParticipantNum, 
                           data = Behave, function(x) sd(x))
agg.ParticipantNum_se = agg.ParticipantNum_sd$Accuracy/sqrt(agg.ParticipantNum_len$Accuracy)
agg.ParticipantNum$se = agg.ParticipantNum_se
```

```{r}
library(ggplot2)
gp <- ggplot(agg.ParticipantNum , aes(x=ParticipantNum, y=Accuracy)) +
  geom_col( size=.05, color = "black",show.legend = FALSE,width = 0.6) + 
  scale_fill_grey()+
  geom_errorbar(aes(ymax=Accuracy+se, ymin=Accuracy-se), width=.1,size = 0.2, color = 'black')+
  theme_classic() + 
  scale_y_continuous(labels = scales::percent) +
  xlab("Participants") +
  ylab("Accuracy Percentage")
gp+coord_flip()
```
The above barplot shows the mean accuracy rate of different participants.

#### Interaction plot
Here I want to plot interaction plot to show interactions for strength level and confidence.

```{r}
## FOR DIFFERENT Confidence 
plot_F_interaction = function(Behave) {
  gp = list()
  # pick first 10 participants
  for (i in 1:10) {
    dataset.par= Behave[which(Behave$ParticipantNum == unique(Behave$ParticipantNum)[i]),]
    ### interaction plots
    agg.stren.conf = aggregate(Accuracy~ResponseTime + StrengthLevel, 
                            data = dataset.par,  mean)

#    gp[[i]] <- ggplot(agg.stren.conf, aes(x=ResponseTime, y=Accuracy, colour=StrengthLevel, #group=StrengthLevel)) +
#      geom_line(aes(linetype=StrengthLevel), size=.5, color = "black",show.legend = FALSE) + 
#      geom_point(aes(shape=StrengthLevel), size=2, color = 'black',show.legend = FALSE) + 
#     # geom_errorbar(aes(ymax=recovery+se, ymin=recovery-se), width=.1,size = 0.2, color = 'black')+
#      theme_classic() + 
#      scale_y_continuous(labels = scales::percent) +
#      xlab("ResponseTime") +
#      ylab("Accuracy Percentage")
    
    gp[[i]] <- qplot(x = ResponseTime, y = Accuracy, data = agg.stren.conf, color = StrengthLevel) +
  geom_smooth(method = "lm") 
  }
  library("gridExtra")
  grid.arrange(gp[[1]], gp[[2]],gp[[3]],gp[[4]],gp[[5]],gp[[6]],gp[[7]],gp[[8]],gp[[9]], gp[[10]], nrow = 5, ncol = 2) 
}
```

```{r}
## FOR DIFFERENT Confidence 
plot_F_interaction = function(Behave) {

  # pick first 10 participants
    ### interaction plots
    agg.stren.conf = aggregate(cbind(Accuracy, ResponseTime,StrengthLevel)~ ParticipantNum ,
                            data = Behave,  mean)
    print(agg.stren.conf)
#    gp[[i]] <- ggplot(agg.stren.conf, aes(x=ResponseTime, y=Accuracy, colour=StrengthLevel, #group=StrengthLevel)) +
#      geom_line(aes(linetype=StrengthLevel), size=.5, color = "black",show.legend = FALSE) + 
#      geom_point(aes(shape=StrengthLevel), size=2, color = 'black',show.legend = FALSE) + 
#     # geom_errorbar(aes(ymax=recovery+se, ymin=recovery-se), width=.1,size = 0.2, color = 'black')+
#      theme_classic() + 
#      scale_y_continuous(labels = scales::percent) +
#      xlab("ResponseTime") +
#      ylab("Accuracy Percentage")
    
    gp <- qplot(x = ResponseTime, y = Accuracy, data = agg.stren.conf, color = StrengthLevel) +
  geom_smooth(method = "lm") 

    gp
}
```


```{r}
plot_F_interaction(Behave)
```

```{r}
library(tidyverse)
glm1 <- glm(Accuracy~StrengthLevel*ResponseTime, data = Behave,
            family = "binomial")
newdf = cbind(Behave, Pred_Logit_Accuracy = predict(glm1))

ggplot(newdf) +
  aes(x = ResponseTime, y = Pred_Logit_Accuracy, color = StrengthLevel) +
  geom_point() +
  geom_line() + 
  scale_color_manual(
        values=c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00"))
```
```{r}
newdf1 = cbind(newdf, Pred_Prob_Accuracy = predict(glm1, type = "response"))
  ggplot(newdf1) +
  aes(x = ResponseTime, y = Pred_Prob_Accuracy, color = StrengthLevel) +
  geom_point() +
  geom_smooth(method = "glm",
              aes(x = ResponseTime, y= Pred_Prob_Accuracy),
              method.args = list(family = "binomial"),
              se = TRUE)+
    scale_color_manual(
        values=c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00"))
```

```{r}
boxplot(ResponseTime~ParticipantNum, data = Behave, xlab="ParticipantNum", ylab="ResponseTime")
boxplot(Accuracy~ParticipantNum, data = Behave, xlab="ParticipantNum", ylab="Accuracy")

agg.ParticipantNum
```

There seems to have mild interactions between strength level and confidence. So when we fit model, we could consider to add interaction terms.


## III. Models
### 3.1 Randomized Block Model
```{r}
L_aov = aov(ResponseTime~StrengthLevel*ParticipantNum, data = Behave)
summary(L_aov)
```

```{r}
par(mfrow=c(2,2))
plot(L_aov)
```

```{r}
CIs_strLevel = TukeyHSD(L_aov, which = 1)
CIs_strLevel
```

```{r}
plot(CIs_strLevel)
```

```{r}
install.packages("DescTools")
library(DescTools)
ScheffeTest(x=L_aov, which="StrengthLevel")
```

### 3.2 GLM Model
Fist we want to fit logistic regression model here with response variable Acc.
```{r}
library(lme4)
logistic_fit1 = glmer(Accuracy~StrengthLevel+ResponseTime+(1|ParticipantNum), data = Behave, family = binomial) 
summary(logistic_fit1)
```

```{r}
logistic_fit2 = glmer(Accuracy~StrengthLevel+(1|ParticipantNum), data = Behave, family = binomial) 
summary(logistic_fit2)
```

```{r}
logistic_fit3 = glmer(Accuracy~ResponseTime+(1|ParticipantNum), data = Behave, family = binomial) 
summary(logistic_fit3)
```


```{r}
library(stargazer)
stargazer(logistic_fit1, logistic_fit2, logistic_fit3, title='Summary Statistics of Model 1',header = FALSE,label="tab:02005",ci=TRUE,digits=3)
```

```{r}
library(lmtest)
lrtest(logistic_fit2, logistic_fit1)
lrtest(logistic_fit3, logistic_fit1)
```

```{r}
library(dplyr)
set.seed(1234)
train = Behave %>% group_by(ParticipantNum, StrengthLevel) %>% sample_n(80)
test = dplyr::anti_join(Behave, train)
train = (rbinom(dim(Behave)[1], 1, 0.8) == 1)
Behave_train = Behave[train, ]
Behave_test = Behave[!train, ]
```

```{r}
install.packages("ROCR")
library(ROCR)
logistic_fit4 = glmer(Accuracy~StrengthLevel+ResponseTime+(1|ParticipantNum), data = train, family = binomial) 
# Compute AUC for predicting Class with the model
prob <- predict(logistic_fit4, newdata=test, type="response")
pred <- prediction(prob, test$Accuracy)
Behave_fit_pred = rep(0, dim(test)[1])
Behave_fit_pred[prob > 0.5] = 1
test_error = mean(Behave_fit_pred != test$Accuracy)
table(Behave_fit_pred, test$Accuracy)
test_error
```

```{r}
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
```


```{r}
install.packages("caret")
library(caret)

confusionMatrix(data=pred, Behave_test$Accuracy)
```


```{r}
plot(fit1$fitted.values, fit1$residuals)
points(loess.smooth(fit1$fitted.values, fit1$residuals), type = "l", lty = 2, col = "red")

```



Response time is significant here, but we can still exclude response time and fit ANOVA to see what will happen.

```{r}
fit2 = glm(Accuracy~ParticipantNum + Confidence + StrengthLevel, data = Behave, family = binomial) # additive model
summary(fit2)
``` 

ANOVA:
```{r}
anova(fit2, test = 'Chi')
```

All are significant.

Check goodness of fit:
```{r}
res.P = residuals(fit1, type="pearson")
res.D = residuals(fit1, type="deviance") #or residuals(fit), by default
boxplot(cbind(res.P, res.D), labels = c("Pearson", "Deviance"))
```

```{r}
par(mfrow=c(1,2))
plot(fit1$fitted.values, res.P, pch=16, cex=0.6, ylab='Pearson Residuals', xlab='Fitted Values')
lines(smooth.spline(fit1$fitted.values, res.P, spar=0.9), col=2)
abline(h=0, lty=2, col='grey')
plot(fit1$fitted.values, res.D, pch=16, cex=0.6, ylab='Deviance Residuals', xlab='Fitted Values')
lines(smooth.spline(fit1$fitted.values, res.D, spar=0.9), col=2)
abline(h=0, lty=2, col='grey')
```

Run tests:
```{r}
library(lawstat)
runs.test(y = res.P, plot.it = TRUE)
title(main='Pearson Residual Runs Test')
runs.test(y = res.D, plot.it = TRUE)
title(main='Deviance Residual Runs Test')
```

Sheffe's Pariwise Comparisions:
```{r}

library(multcomp)
library(agricolae)
par(mfrow = c(1,1))
sheffetest.1 = scheffe.test(fit1,'Confidence')
print(sheffetest.1)
plot(sheffetest.1)

sheffetest.2 = scheffe.test(fit1,'StrengthLevel')
print(sheffetest.2)
plot(sheffetest.2)

```



